Log of Project Changes

RESEARCH PHASE
March 25th - Project idea created
March 26th - Academic advisor at Columbia joined as oversight
March 31st to April 23rd - Started with GPT-JT and switched to bart-large-mnli as main-model for prototype

PROTOTYPE PHASE
April 24th - First prototype with bart-large-mnli and tosdr extracted data tested (bad results, see below)
April 25th - Added two collaborators to the project (had brainstorm meeting)
May 1st - Decided to use databases for storage of data to maximize speed (over json and csv)

BACKEND DEVELOPMENT & FRONTEND PROTOTYPE PHASE
May 5th - Created relevance labeling to generate training data for the classifier (hand labeled 600 sentences)
May 6th - Converted ml training data to csv format for ease of use with pandas and ml code
May 10th to May 23rd - Training started at 70% and moved to 87% for the relevance machine learning model (involved preprocessing to remove bad characters)
May 24th - ai1 for relevance classification hits 90% accuracy
May 26th to May 31st - Quote augmenting ml model implemented to create 100 examples of each case for training of case classifier ai (switched from chatgpt to parrot)
May 31st - First website design implemented at a test phase
June 1st to June 24th - Began training ai2 (pivoted from bart-large-mnli to bert-large-cased to bert-base-cased to bart-large-mnli)
June 22nd - Achieved 93% accuracy on ai2 case selection with 30 epochs over 15 hours of training
June 24th - Intensive testing on ai reveals faults, transition back to bart-large-mnli (semi accurate compared to tosdr, but very accurate in finding valid alternatives)

MATURE BACKEND & FRONTEND DEVELOPMENT PHASE
July 1st - New database code and format adopted for storing all ai results
July 2nd - Website design plan finalized
July 4th - Calculation code for new database shifted to softmax w/ multi_label as false
July 9th - Alpha service set selected (16 services, 88 policies), double mnli run gives promising 
July 10th - 404 page and frontend basics complete
July 17th - Alpha frontend pages and design finished and sql integration in progress
July 18th - Alpha database optimized and reduced from 280 mb to 40 mb on alpha service set
July 19th - Database successfully linked to services page (on local machine, issue w/ vercel deployment)
July 21st - About page and donation site created completed
July 25th - Prisma adopted as ORM to replace personal APIs

ALPHA PHASE
July 26th - Alpha launched!
July 28th - Contributors, roadmap, and hamburger menu added; service page redesigned
August 1st - Search and service function added through AWS PostgreSQL RDS attached by prisma
August 7th - Backend transfer to PostgreSQL and client-side calculations prototyped for personalized grading
August 10th - Vectorized case to sentence comparison reduces case applier ai from 6 to 0.2 seconds per sentence
August 11th - Hyperefficient database schema adopted and case applier model shifted to distilbart 12-3 (sentence time down to 0.1 secs)
August 16th - New service page finalized
August 21st - Frontend database migrated to the new schema
August 22nd - Add a service and login/signup prototypes created; new project logo
September 6th - Cosine similarity and relevance model experimentation yields bad results
September 10th - Nextauth login backend and frontend integrated
September 12th - Authenticated user page and api routes established
September 15th - No relevance to straight case classification has best results for scoring
September 17th - Tentative scoring equation found after expermentation with limit function, e constants, and data fitting
September 21st - Case sorting for service card calculations shifted to client side, new scoring scheme with tailored effectiveness
September 24th - Sign up api routes seperated, preferences prototype deployed, mobile scaling patches across the board
September 30th - Meeting with math doctorate to discuss the nuances of calculating scores
October 4th - Manual processing of 100 beta sources for link cleaning and proper sentence pulling
October 13th - Project submitted to ycombinator winter 2024 batch
October 17th - Gradient descent tests yield good results on small dataset but not large one
October 24th - Application for two project grants worth roughly $10k
October 29th - Member benefits page working prototype and api patches (add a service activated)
November 9th - Huge swaths of data pulled from usableprivacy.org for relevance training, results still lacking
November 14th - Multiple choice AI model has preliminary testing along with question answering (mediocre results)
November 18th - Complete case rewrite with standardized diction and syntax, categories are also created for score grouping and ai processing
November 23rd - Prototype question answering to multiple choice has extremely promising results
November 24th - New prototype for cards and services to work with new category model
November 25th - Critical security patches and code cleaning
November 29th - Backend database and scraper class creation
December 5th - Back to the ai drawing board with an analysis of similar databases like RACE to find good models
December 10th - Case updates withe question and categroy modification for improved performance
December 16th - Full transition away from flan and into new roberta model pipeline development
December 20th - Roberta pipeline prototype completed with optimization underway

BETA PHASE
tbd - Beta launched!

PRODUCTION PHASE
tbd - Project launched!


April prototype results
# Reddit = -2,083,457 https://www.redditinc.com/policies/privacy-policy
# Duckduckgo = -2,660,479 https://duckduckgo.com/privacy
# Spotify = -10,327,305 https://www.spotify.com/us/legal/privacy-policy/
# Startpage = 464,114 https://www.startpage.com/en/privacy-policy/
# Proton = -943,446 https://proton.me/legal/privacy
# Apple = -3,991,176 https://www.apple.com/legal/privacy/en-ww/
# Paypal = -2,813,848 https://www.paypal.com/us/legalhub/privacy-full

July pre-normalized score results
# Reddit = 7.79
# Duckduckgo = 8.09
# Spotify = 7.6
# Startpage = 8.33
# Proton = N/A
# Apple = 7.59
# Paypal = 7.52